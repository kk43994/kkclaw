// ğŸ™ï¸ æ™ºèƒ½è¯­éŸ³æ’­æŠ¥ç³»ç»Ÿ - å¢å¼ºç‰ˆï¼ˆæ”¯æŒ MiniMax Speech / DashScope CosyVoiceï¼‰
const { exec } = require('child_process');
const { promisify } = require('util');
const execAsync = promisify(exec);
const path = require('path');
const fs = require('fs').promises;
const DashScopeTTS = require('./voice/dashscope-tts');
const MiniMaxTTS = require('./voice/minimax-tts');

class SmartVoiceSystem {
    constructor(petConfig) {
        this.petConfig = petConfig || null;
        this.isSpeaking = false;
        this.tempDir = path.join(__dirname, 'temp');
        this.voice = 'zh-CN-XiaoxiaoNeural';  // Edge TTS é»˜è®¤æ™“æ™“
        this.enabled = true;
        this.queue = [];
        this.maxQueueSize = 10;
        this.lastSpoken = '';
        this.lastSpokenTime = 0;
        
        // ğŸ­ æƒ…å¢ƒæ¨¡å¼
        this.contextMode = 'normal';  // normal, excited, calm, urgent
        
        // ğŸ™ï¸ TTS å¼•æ“é€‰æ‹©: 'minimax' | 'dashscope' | 'edge'
        this.ttsEngine = 'minimax';  // é»˜è®¤ä½¿ç”¨ MiniMax Speech 2.5
        
        // ğŸ”‘ MiniMax é…ç½®
        this.minimax = null;
        this.minimaxVoiceId = 'xiaotuantuan_minimax';  // ğŸ¤ å°å›¢å›¢å…‹éš†éŸ³è‰²
        this.minimaxModel = 'speech-2.5-turbo-preview';
        this.minimaxEmotion = 'happy';  // é»˜è®¤å¼€å¿ƒ
        this.initMiniMax();
        
        // ğŸ”‘ DashScope é…ç½® (å¤‡ç”¨)
        this.dashscope = null;
        this.dashscopeVoice = 'cosyvoice-v3-plus-tuantuan-28c7ca7e915943a081ab7ece12916d28';  // ğŸ¤ å°å›¢å›¢å…‹éš†éŸ³è‰²
        this.dashscopeModel = 'cosyvoice-v3-plus';  // v3-plus æ¨¡å‹ï¼ˆå£°éŸ³å¤åˆ»æœ€ä½³ï¼‰
        this.initDashScope();
        
        // ğŸ“Š ç»Ÿè®¡æ•°æ®
        this.stats = {
            totalSpoken: 0,
            totalSkipped: 0,
            totalQueued: 0,
            avgDuration: 0
        };
        
        this.initTempDir();
    }

    /**
     * ğŸ”‘ åˆå§‹åŒ– MiniMax TTS
     */
    initMiniMax() {
        try {
            const config = this.loadConfig();
            const apiKey = process.env.MINIMAX_API_KEY || config.minimax?.apiKey || '';
            if (apiKey) {
                this.minimax = new MiniMaxTTS({
                    apiKey: apiKey,
                    model: config.minimax?.model || this.minimaxModel,
                    voiceId: config.minimax?.voiceId || this.minimaxVoiceId,
                    speed: config.minimax?.speed || 1.1,
                    vol: config.minimax?.vol || 3.0,
                    emotion: config.minimax?.emotion || this.minimaxEmotion,
                    tempDir: this.tempDir
                });
                console.log('[Voice] ğŸ™ï¸ MiniMax Speech å¼•æ“å·²åˆå§‹åŒ– (å°å›¢å›¢å…‹éš†éŸ³è‰² + æƒ…æ„Ÿæ§åˆ¶)');
            } else {
                console.log('[Voice] âš ï¸ MiniMax API Key æœªè®¾ç½®');
                if (this.ttsEngine === 'minimax') {
                    this.ttsEngine = 'dashscope';
                    console.log('[Voice] å›é€€åˆ° DashScope');
                }
            }
        } catch (err) {
            console.error('[Voice] âŒ MiniMax åˆå§‹åŒ–å¤±è´¥:', err.message);
            if (this.ttsEngine === 'minimax') {
                this.ttsEngine = 'dashscope';
            }
        }
    }

    /**
     * ğŸ“„ åŠ è½½é…ç½®ï¼ˆä¼˜å…ˆä½¿ç”¨ petConfig å®ä¾‹è·å–å·²è§£å¯†çš„å€¼ï¼‰
     */
    loadConfig() {
        if (this.petConfig) {
            return {
                minimax: this.petConfig.get('minimax') || {},
                dashscope: this.petConfig.get('dashscope') || {},
                ttsEngine: this.petConfig.get('ttsEngine'),
                voiceEnabled: this.petConfig.get('voiceEnabled'),
            };
        }
        // Fallback: ç›´æ¥è¯»æ–‡ä»¶ï¼ˆæ— æ³•è§£å¯†ï¼‰
        try {
            const configPath = path.join(__dirname, 'pet-config.json');
            const fsSync = require('fs');
            if (fsSync.existsSync(configPath)) {
                return JSON.parse(fsSync.readFileSync(configPath, 'utf8'));
            }
        } catch (err) {}
        return {};
    }

    /**
     * ğŸ”‘ åˆå§‹åŒ– DashScope TTS
     */
    initDashScope() {
        try {
            // ä»ç¯å¢ƒå˜é‡æˆ–é…ç½®æ–‡ä»¶è¯»å– API Key
            const apiKey = process.env.DASHSCOPE_API_KEY || this.loadApiKeyFromConfig();
            if (apiKey) {
                this.dashscope = new DashScopeTTS({
                    apiKey: apiKey,
                    voice: this.dashscopeVoice,
                    model: this.dashscopeModel || 'cosyvoice-v3-plus',
                    tempDir: this.tempDir
                });
                console.log('[Voice] ğŸ™ï¸ DashScope CosyVoice å¼•æ“å·²åˆå§‹åŒ– (å°å›¢å›¢éŸ³è‰²)');
            } else {
                console.log('[Voice] âš ï¸ DashScope API Key æœªè®¾ç½®ï¼Œå›é€€åˆ° Edge TTS');
                this.ttsEngine = 'edge';
            }
        } catch (err) {
            console.error('[Voice] âŒ DashScope åˆå§‹åŒ–å¤±è´¥:', err.message);
            this.ttsEngine = 'edge';
        }
    }

    /**
     * ğŸ“„ ä»é…ç½®åŠ è½½ DashScope API Key
     */
    loadApiKeyFromConfig() {
        if (this.petConfig) {
            const dashscope = this.petConfig.get('dashscope') || {};
            return dashscope.apiKey || '';
        }
        // Fallback: ç›´æ¥è¯»æ–‡ä»¶ï¼ˆæ— æ³•è§£å¯†ï¼‰
        try {
            const configPath = path.join(__dirname, 'pet-config.json');
            const fsSync = require('fs');
            if (fsSync.existsSync(configPath)) {
                const config = JSON.parse(fsSync.readFileSync(configPath, 'utf8'));
                return config.dashscope?.apiKey || config.dashscopeApiKey || '';
            }
        } catch (err) {}
        return '';
    }

    async initTempDir() {
        try {
            await fs.mkdir(this.tempDir, { recursive: true });
        } catch (err) {}
    }

    /**
     * ğŸ¯ æ™ºèƒ½æ’­æŠ¥å…¥å£
     * @param {string} text - è¦æ’­æŠ¥çš„æ–‡æœ¬
     * @param {object} options - é€‰é¡¹ { priority, context, emotion }
     */
    async speak(text, options = {}) {
        if (!this.enabled) {
            console.log('ğŸ”‡ è¯­éŸ³å·²å…³é—­');
            return;
        }
        
        // ğŸ¯ æ™ºèƒ½å†…å®¹åˆ†æå’Œä¼˜åŒ–
        const analysis = this.analyzeContent(text);
        
        // ğŸ­ å¦‚æœå¤–éƒ¨ä¼ å…¥äº† emotionï¼Œä¼˜å…ˆä½¿ç”¨ï¼ˆæ¯”è‡ªåŠ¨æ£€æµ‹æ›´å‡†ï¼‰
        if (options.emotion) {
            analysis.emotion = options.emotion;
            console.log(`[Voice] ğŸ­ ä½¿ç”¨å¤–éƒ¨æƒ…ç»ª: ${options.emotion}`);
        }
        
        if (analysis.skip) {
            this.stats.totalSkipped++;
            console.log(`â­ï¸ ${analysis.reason}`);
            return;
        }
        
        // ğŸ­ æ ¹æ®å†…å®¹è°ƒæ•´è¯­éŸ³ç‰¹æ€§
        const voiceConfig = this.selectVoice(analysis);
        
        // ğŸ”Š é˜Ÿåˆ—ç®¡ç†
        if (this.isSpeaking) {
            if (options.priority === 'high' || analysis.priority === 'high') {
                // é«˜ä¼˜å…ˆçº§æ’é˜Ÿ
                this.queue.unshift({ text, voiceConfig, analysis });
                console.log(`ğŸš¨ ä¼˜å…ˆçº§æ’é˜Ÿ (æ’é˜Ÿ: ${this.queue.length})`);
            } else if (this.queue.length < this.maxQueueSize) {
                this.queue.push({ text, voiceConfig, analysis });
                this.stats.totalQueued++;
                console.log(`ğŸ“ åŠ å…¥é˜Ÿåˆ— (æ’é˜Ÿ: ${this.queue.length})`);
            } else {
                console.log('âš ï¸ é˜Ÿåˆ—å·²æ»¡');
            }
            return;
        }

        await this.speakNow(text, voiceConfig, analysis);
        await this.processQueue();
    }

    /**
     * ğŸ“Š æ™ºèƒ½å†…å®¹åˆ†æ
     */
    analyzeContent(text) {
        const analysis = {
            skip: false,
            reason: '',
            priority: 'normal',
            emotion: 'neutral',
            category: 'general',
            processedText: text
        };
        
        // 1. åŸºç¡€è¿‡æ»¤
        if (text.length < 2) {
            analysis.skip = true;
            analysis.reason = 'å†…å®¹è¿‡çŸ­';
            return analysis;
        }
        
        if (/^[\s.,;!?ã€‚ï¼Œï¼›ï¼ï¼Ÿ]+$/.test(text)) {
            analysis.skip = true;
            analysis.reason = 'çº¯æ ‡ç‚¹';
            return analysis;
        }
        
        // 2. å»é‡æ£€æµ‹
        if (this.lastSpoken === text && Date.now() - this.lastSpokenTime < 5000) {
            analysis.skip = true;
            analysis.reason = 'é‡å¤å†…å®¹';
            return analysis;
        }
        
        // 3. å†…å®¹åˆ†ç±»å’Œä¼˜å…ˆçº§
        if (text.match(/ğŸ”¥|ç´§æ€¥|é”™è¯¯|å´©æºƒ|å¤±è´¥/)) {
            analysis.priority = 'high';
            analysis.emotion = 'urgent';
            analysis.category = 'error';
        } else if (text.match(/âœ…|å®Œæˆ|æˆåŠŸ|å¥½/)) {
            analysis.emotion = 'happy';
            analysis.category = 'success';
        } else if (text.match(/âš ï¸|è­¦å‘Š|æ³¨æ„/)) {
            analysis.priority = 'medium';
            analysis.emotion = 'concern';
            analysis.category = 'warning';
        } else if (text.match(/ğŸ“Š|ç›‘æ§|æ€§èƒ½|ç»Ÿè®¡/)) {
            analysis.category = 'data';
        } else if (text.match(/ğŸ‰|æ­å–œ|å¤ªå¥½äº†/)) {
            analysis.emotion = 'excited';
            analysis.category = 'celebration';
        }
        
        // 4. æ™ºèƒ½æ–‡æœ¬é¢„å¤„ç†
        analysis.processedText = this.enhanceText(text, analysis);
        
        return analysis;
    }

    /**
     * âœ¨ å¢å¼ºæ–‡æœ¬ - è®©æ’­æŠ¥æ›´è‡ªç„¶
     */
    enhanceText(text, analysis) {
        let enhanced = text;
        
        // 1. æ¸…ç†ç‰¹æ®Šå­—ç¬¦
        enhanced = this.cleanTextForSpeech(enhanced);
        
        // 2. æ ¹æ®æƒ…å¢ƒæ·»åŠ è¯­æ°”è¯
        if (analysis.emotion === 'happy') {
            // æˆåŠŸçš„äº‹æƒ…ï¼Œè¯­æ°”æ›´è½»å¿«
            if (!enhanced.match(/[ï¼Œã€‚ï¼]$/)) {
                enhanced += 'ï¼';
            }
        } else if (analysis.emotion === 'urgent') {
            // ç´§æ€¥æƒ…å†µï¼Œæ›´ç®€æ´ç›´æ¥
            enhanced = enhanced.replace(/æ­£åœ¨|å‡†å¤‡/, '');
        }
        
        // 3. æ™ºèƒ½æ–­å¥ - è®©æ’­æŠ¥æœ‰èŠ‚å¥
        enhanced = this.addNaturalPauses(enhanced);
        
        // 4. å£è¯­åŒ–å¤„ç†
        enhanced = this.makeConversational(enhanced);
        
        return enhanced;
    }

    /**
     * ğŸµ æ·»åŠ è‡ªç„¶åœé¡¿
     */
    addNaturalPauses(text) {
        let paused = text;
        
        // åœ¨å…³é”®ä½ç½®æ·»åŠ åœé¡¿
        paused = paused.replace(/ï¼Œ/g, 'ï¼Œ ')           // é€—å·åçŸ­åœé¡¿
                       .replace(/ã€‚/g, 'ã€‚ ')           // å¥å·åé•¿åœé¡¿
                       .replace(/ï¼/g, 'ï¼ ')           // æ„Ÿå¹å·ååœé¡¿
                       .replace(/\s+/g, ' ')            // æ¸…ç†å¤šä½™ç©ºæ ¼
                       .trim();
        
        return paused;
    }

    /**
     * ğŸ’¬ å£è¯­åŒ–å¤„ç†
     */
    makeConversational(text) {
        let conversational = text;
        
        // æŠ€æœ¯æœ¯è¯­å£è¯­åŒ–
        const replacements = {
            'API': 'æ¥å£',
            'URL': 'ç½‘å€',
            'JSON': 'æ•°æ®',
            'HTTP': '',
            'IPC': 'é€šä¿¡',
            'CPU': 'å¤„ç†å™¨',
            'GB': 'å‰å­—èŠ‚',
            'MB': 'å…†å­—èŠ‚',
            'KB': 'åƒå­—èŠ‚',
            'error': 'é”™è¯¯',
            'success': 'æˆåŠŸ',
            'failed': 'å¤±è´¥',
            'warning': 'è­¦å‘Š',
            'OK': 'å¥½çš„',
            'npm': '',
            'node': '',
            '.js': 'è„šæœ¬',
            '.json': 'é…ç½®',
            'undefined': 'æœªå®šä¹‰',
            'null': 'ç©ºå€¼'
        };
        
        for (const [tech, speak] of Object.entries(replacements)) {
            const regex = new RegExp(tech, 'gi');
            conversational = conversational.replace(regex, speak);
        }
        
        // æ•°å­—è¯»æ³•ä¼˜åŒ–
        conversational = conversational.replace(/(\d+)MB/g, '$1å…†')
                                       .replace(/(\d+)GB/g, '$1G')
                                       .replace(/(\d+)%/g, 'ç™¾åˆ†ä¹‹$1');
        
        // æ·»åŠ è‡ªç„¶çš„è¿æ¥è¯
        if (conversational.match(/^(å®Œæˆ|æˆåŠŸ|å¥½|æ”¶åˆ°)$/)) {
            conversational += 'äº†';
        }
        
        return conversational;
    }

    /**
     * ğŸ­ æ ¹æ®å†…å®¹é€‰æ‹©è¯­éŸ³
     */
    selectVoice(analysis) {
        let config = {
            voice: this.voice,
            rate: '+0%',    // è¯­é€Ÿ
            pitch: '+0Hz'   // éŸ³è°ƒ
        };
        
        // æ ¹æ®æƒ…å¢ƒè°ƒæ•´è¯­éŸ³ç‰¹æ€§
        switch (analysis.emotion) {
            case 'excited':
            case 'happy':
                config.rate = '+10%';   // ç¨å¿«
                config.pitch = '+30Hz'; // å¼€å¿ƒ
                break;
            case 'surprised':
                config.rate = '+15%';   // æ›´å¿«
                config.pitch = '+40Hz'; // æƒŠè®¶è¯­è°ƒé«˜
                break;
            case 'urgent':
            case 'fearful':
                config.rate = '+10%';
                config.voice = 'zh-CN-YunxiNeural';  // æ¢ç”·å£°ï¼Œæ›´æœ‰åŠ›
                break;
            case 'sad':
                config.rate = '-5%';    // ç¨æ…¢
                config.pitch = '-10Hz'; // ä½æ²‰ä¸€ç‚¹
                break;
            case 'thinking':
                config.rate = '-5%';    // æ€è€ƒæ—¶æ…¢ä¸€ç‚¹
                config.pitch = '+10Hz';
                break;
            case 'calm':
                config.rate = '-5%';    // å¹³é™èˆ’ç¼“
                config.pitch = '+15Hz';
                break;
            case 'angry':
                config.rate = '+5%';
                config.pitch = '+20Hz';
                break;
            default:
                config.pitch = '+15Hz';
                break;
        }
        
        return config;
    }

    /**
     * ğŸ”Š ç«‹å³æ’­æŠ¥
     */
    async speakNow(text, voiceConfig, analysis) {
        this.isSpeaking = true;
        const startTime = Date.now();
        
        try {
            const cleanText = analysis.processedText || this.cleanTextForSpeech(text);
            
            if (!cleanText.trim()) {
                console.log('âš ï¸ æ¸…ç†åæ–‡æœ¬ä¸ºç©º');
                return;
            }
            
            // è®°å½•æ’­æŠ¥
            this.lastSpoken = text;
            this.lastSpokenTime = Date.now();
            this.stats.totalSpoken++;
            
            // ç”Ÿæˆè¯­éŸ³
            const outputFile = path.join(this.tempDir, `speech_${Date.now()}.mp3`);
            
            // æ˜¾ç¤ºæ’­æŠ¥å†…å®¹ï¼ˆå¸¦åˆ†ç±»æ ‡ç­¾ï¼‰
            const categoryIcon = {
                'success': 'âœ…',
                'error': 'ğŸ”¥',
                'warning': 'âš ï¸',
                'data': 'ğŸ“Š',
                'celebration': 'ğŸ‰',
                'general': 'ğŸ”Š'
            }[analysis.category] || 'ğŸ”Š';
            
            console.log(`${categoryIcon} æ’­æŠ¥: ${cleanText.substring(0, 40)}${cleanText.length > 40 ? '...' : ''}`);
            
            // ğŸ™ï¸ æ ¹æ®å¼•æ“é€‰æ‹© TTS æ–¹å¼
            if (this.ttsEngine === 'minimax' && this.minimax) {
                // MiniMax Speech 2.5 (å¸¦æƒ…æ„Ÿæ§åˆ¶)
                try {
                    // ä¼˜å…ˆç”¨ analysis ä¼ å…¥çš„ emotionï¼Œå¦åˆ™è‡ªåŠ¨æ£€æµ‹
                    const emotion = (['happy','sad','angry','fearful','disgusted','surprised','calm'].includes(analysis.emotion))
                        ? analysis.emotion 
                        : MiniMaxTTS.detectEmotion(cleanText);
                    console.log(`[Voice] ğŸ­ TTSæƒ…ç»ª: ${emotion} (æ¥æº: ${analysis.emotion === emotion ? 'å¤–éƒ¨æŒ‡å®š' : 'è‡ªåŠ¨æ£€æµ‹'})`);
                    const audioFile = await this.minimax.synthesize(cleanText, {
                        voiceId: this.minimaxVoiceId,
                        emotion: emotion,
                        outputFile: outputFile
                    });
                    
                    // PowerShell æ’­æ”¾
                    const playCmd = `powershell -c "Add-Type -AssemblyName presentationCore; $player = New-Object System.Windows.Media.MediaPlayer; $player.Open('${audioFile}'); $player.Play(); while($player.NaturalDuration.HasTimeSpan -eq $false) { Start-Sleep -Milliseconds 100 }; $duration = $player.NaturalDuration.TimeSpan.TotalSeconds; Start-Sleep -Seconds $duration; $player.Close()"`;
                    await execAsync(playCmd, { timeout: 120000, windowsHide: true });
                    
                } catch (minimaxErr) {
                    console.error('[Voice] âŒ MiniMax å¤±è´¥ï¼Œå›é€€åˆ° DashScope:', minimaxErr.message);
                    // ğŸš¨ å‘é€é™çº§é€šçŸ¥
                    this.notifyDegradation('minimax', 'dashscope', minimaxErr.message);
                    // å›é€€åˆ° DashScope
                    if (this.dashscope) {
                        try {
                            const audioFile = await this.dashscope.synthesize(cleanText, {
                                voice: this.dashscopeVoice,
                                outputFile: outputFile
                            });
                            const playCmd = `powershell -c "Add-Type -AssemblyName presentationCore; $player = New-Object System.Windows.Media.MediaPlayer; $player.Open('${audioFile}'); $player.Play(); while($player.NaturalDuration.HasTimeSpan -eq $false) { Start-Sleep -Milliseconds 100 }; $duration = $player.NaturalDuration.TimeSpan.TotalSeconds; Start-Sleep -Seconds $duration; $player.Close()"`;
                            await execAsync(playCmd, { timeout: 120000, windowsHide: true });
                        } catch (dashErr) {
                            console.error('[Voice] âŒ DashScope ä¹Ÿå¤±è´¥ï¼Œå›é€€åˆ° Edge TTS:', dashErr.message);
                            // ğŸš¨ å‘é€äºŒçº§é™çº§é€šçŸ¥
                            this.notifyDegradation('dashscope', 'edge', dashErr.message);
                            await this.speakWithEdgeTTS(cleanText, voiceConfig, outputFile);
                        }
                    } else {
                        await this.speakWithEdgeTTS(cleanText, voiceConfig, outputFile);
                    }
                }
            } else if (this.ttsEngine === 'dashscope' && this.dashscope) {
                // DashScope CosyVoice
                try {
                    const audioFile = await this.dashscope.synthesize(cleanText, {
                        voice: this.dashscopeVoice,
                        outputFile: outputFile
                    });
                    
                    // PowerShell æ’­æ”¾
                    const playCmd = `powershell -c "Add-Type -AssemblyName presentationCore; $player = New-Object System.Windows.Media.MediaPlayer; $player.Open('${audioFile}'); $player.Play(); while($player.NaturalDuration.HasTimeSpan -eq $false) { Start-Sleep -Milliseconds 100 }; $duration = $player.NaturalDuration.TimeSpan.TotalSeconds; Start-Sleep -Seconds $duration; $player.Close()"`;
                    await execAsync(playCmd, { timeout: 120000, windowsHide: true });

                } catch (dashErr) {
                    console.error('[Voice] âŒ DashScope å¤±è´¥ï¼Œå›é€€åˆ° Edge TTS:', dashErr.message);
                    // ğŸš¨ å‘é€é™çº§é€šçŸ¥
                    this.notifyDegradation('dashscope', 'edge', dashErr.message);
                    // å›é€€åˆ° Edge TTS
                    await this.speakWithEdgeTTS(cleanText, voiceConfig, outputFile);
                }
            } else {
                // Edge TTS (å›é€€æ–¹æ¡ˆ)
                await this.speakWithEdgeTTS(cleanText, voiceConfig, outputFile);
            }
            
            const duration = (Date.now() - startTime) / 1000;
            this.stats.avgDuration = (this.stats.avgDuration * (this.stats.totalSpoken - 1) + duration) / this.stats.totalSpoken;
            
            console.log(`âœ… æ’­æ”¾å®Œæˆ (${duration.toFixed(1)}ç§’)`);

            // ğŸ§¹ æ¯ 20 æ¬¡æ’­æŠ¥è‡ªåŠ¨æ¸…ç†æ—§æ–‡ä»¶ï¼Œä¿ç•™æœ€è¿‘ 30 ä¸ª
            if (this.stats.totalSpoken % 20 === 0) {
                this.cleanupTempFiles(30).catch(() => {});
            }

        } catch (err) {
            console.error('ğŸ™ï¸ æ’­æŠ¥å¤±è´¥:', err.message);
        } finally {
            this.isSpeaking = false;
        }
    }

    async processQueue() {
        if (this.queue.length > 0 && !this.isSpeaking) {
            const next = this.queue.shift();
            console.log(`ğŸ”Š é˜Ÿåˆ—æ’­æŠ¥ (å‰©ä½™: ${this.queue.length})`);
            await this.speakNow(next.text, next.voiceConfig, next.analysis);
            // ç»§ç»­å¤„ç†é˜Ÿåˆ—
            if (this.queue.length > 0) {
                setTimeout(() => this.processQueue(), 500);
            }
        }
    }

    /**
     * ğŸ§¹ æ–‡æœ¬æ¸…ç†ï¼ˆåŸºç¡€ç‰ˆæœ¬ï¼‰
     */
    cleanTextForSpeech(text) {
        let cleaned = text;
        
        // Emoji ç§»é™¤
        cleaned = cleaned.replace(/[\u{1F600}-\u{1F64F}]/gu, '')
                         .replace(/[\u{1F300}-\u{1F5FF}]/gu, '')
                         .replace(/[\u{1F680}-\u{1F6FF}]/gu, '')
                         .replace(/[\u{1F900}-\u{1F9FF}]/gu, '')
                         .replace(/[\u{2600}-\u{26FF}]/gu, '')
                         .replace(/[\u{2700}-\u{27BF}]/gu, '');
        
        // å¸¸è§ç¬¦å·æ›¿æ¢
        cleaned = cleaned.replace(/âœ…/g, 'å®Œæˆ')
                         .replace(/âŒ/g, 'å¤±è´¥')
                         .replace(/âš ï¸/g, 'æ³¨æ„')
                         .replace(/ğŸš€/g, '')
                         .replace(/[ğŸ“¢ğŸ’¡ğŸ”§ğŸ“ğŸ“¸ğŸ“¤ğŸ”Šâš™ï¸]/g, '');
        
        // Markdown æ¸…ç†
        cleaned = cleaned.replace(/\*\*(.*?)\*\*/g, '$1')
                         .replace(/\*(.*?)\*/g, '$1')
                         .replace(/`(.*?)`/g, '$1')
                         .replace(/\[(.*?)\]\(.*?\)/g, '$1');
        
        // ç‰¹æ®Šç¬¦å·æ¸…ç†ï¼ˆä¿ç•™ MiniMax TTS åœé¡¿æ ‡è®° <#X#>ï¼‰
        cleaned = cleaned.replace(/<#([\d.]+)#>/g, 'TPAUSE$1TEND');  // æš‚å­˜åœé¡¿æ ‡è®°
        cleaned = cleaned.replace(/[ã€ã€‘\[\]{}ã€Œã€_~#@]/g, '');
        cleaned = cleaned.replace(/TPAUSE([\d.]+)TEND/g, '<#$1#>');  // æ¢å¤åœé¡¿æ ‡è®°
        
        // é•¿åº¦é™åˆ¶
        if (cleaned.length > 800) {
            cleaned = cleaned.substring(0, 800) + 'ï¼Œç­‰å…±' + cleaned.length + 'å­—';
        }
        
        // ç©ºæ ¼æ¸…ç†
        cleaned = cleaned.replace(/\s+/g, ' ').trim();
        
        return cleaned;
    }

    /**
     * ğŸ“Š è·å–ç»Ÿè®¡
     */
    getStats() {
        return {
            ...this.stats,
            queueLength: this.queue.length,
            isSpeaking: this.isSpeaking,
            enabled: this.enabled
        };
    }

    /**
     * ğŸ›ï¸ è®¾ç½®æ¨¡å¼
     */
    setMode(mode) {
        this.contextMode = mode;
        console.log(`ğŸ­ åˆ‡æ¢æ’­æŠ¥æ¨¡å¼: ${mode}`);
    }

    /**
     * ğŸ”‡ å¼€å…³è¯­éŸ³
     */
    toggle(enabled) {
        this.enabled = enabled;
        console.log(`ğŸ”Š è¯­éŸ³${enabled ? 'å¼€å¯' : 'å…³é—­'}`);
    }

    clearQueue() {
        this.queue = [];
    }

    stop() {
        this.clearQueue();
        this.isSpeaking = false;
    }

    /**
     * ğŸ”Š ä½¿ç”¨ Edge TTS æ’­æŠ¥ï¼ˆå›é€€æ–¹æ¡ˆï¼‰
     */
    async speakWithEdgeTTS(cleanText, voiceConfig, outputFile) {
        let ttsCmd = `python -m edge_tts --voice "${voiceConfig.voice}" --text "${cleanText.replace(/"/g, '').replace(/\n/g, ' ')}" --write-media "${outputFile}"`;
        
        if (voiceConfig.rate !== '+0%') {
            ttsCmd += ` --rate="${voiceConfig.rate}"`;
        }
        if (voiceConfig.pitch !== '+0Hz') {
            ttsCmd += ` --pitch="${voiceConfig.pitch}"`;
        }
        
        await execAsync(ttsCmd, { timeout: 30000, windowsHide: true });

        const playCmd = `powershell -c "Add-Type -AssemblyName presentationCore; $player = New-Object System.Windows.Media.MediaPlayer; $player.Open('${outputFile}'); $player.Play(); while($player.NaturalDuration.HasTimeSpan -eq $false) { Start-Sleep -Milliseconds 100 }; $duration = $player.NaturalDuration.TimeSpan.TotalSeconds; Start-Sleep -Seconds $duration; $player.Close()"`;
        await execAsync(playCmd, { timeout: 120000, windowsHide: true });
    }

    /**
     * ğŸ™ï¸ åˆ‡æ¢ TTS å¼•æ“
     */
    setEngine(engine) {
        if (engine === 'dashscope' && !this.dashscope) {
            console.log('[Voice] âš ï¸ DashScope æœªåˆå§‹åŒ–ï¼Œæ— æ³•åˆ‡æ¢');
            return false;
        }
        this.ttsEngine = engine;
        console.log(`[Voice] ğŸ™ï¸ TTS å¼•æ“åˆ‡æ¢ä¸º: ${engine}`);
        return true;
    }

    /**
     * ğŸ­ è®¾ç½® DashScope éŸ³è‰²
     */
    setDashScopeVoice(voice) {
        this.dashscopeVoice = voice;
        if (this.dashscope) {
            this.dashscope.voice = voice;
        }
        console.log(`[Voice] ğŸ­ DashScope éŸ³è‰²åˆ‡æ¢ä¸º: ${voice}`);
    }

    /**
     * ğŸš¨ å‘é€é™çº§é€šçŸ¥åˆ° OpenClaw
     */
    async notifyDegradation(fromEngine, toEngine, errorMessage) {
        try {
            const https = require('https');
            const http = require('http');
            
            // åˆ¤æ–­é”™è¯¯åŸå› 
            let reason = 'æœªçŸ¥é”™è¯¯';
            let suggestion = '';
            
            if (errorMessage.includes('quota') || errorMessage.includes('balance') || errorMessage.includes('insufficient')) {
                reason = 'é¢åº¦ç”¨å®Œ';
                suggestion = `${fromEngine === 'minimax' ? 'MiniMax' : 'DashScope'} API é¢åº¦å·²ç”¨å®Œï¼Œè¯·å‰å¾€å®˜ç½‘å……å€¼ç»­è´¹`;
            } else if (errorMessage.includes('timeout') || errorMessage.includes('ETIMEDOUT') || errorMessage.includes('ECONNREFUSED')) {
                reason = 'ç½‘ç»œè¶…æ—¶';
                suggestion = 'ç½‘ç»œè¿æ¥å¤±è´¥ï¼Œè¯·æ£€æŸ¥ç½‘ç»œçŠ¶æ€';
            } else if (errorMessage.includes('401') || errorMessage.includes('403') || errorMessage.includes('Unauthorized')) {
                reason = 'API Key æ— æ•ˆ';
                suggestion = 'è¯·æ£€æŸ¥ API Key æ˜¯å¦æ­£ç¡®';
            } else if (errorMessage.includes('429') || errorMessage.includes('rate limit')) {
                reason = 'è¯·æ±‚é¢‘ç‡è¿‡é«˜';
                suggestion = 'è§¦å‘é™æµï¼Œè¯·ç¨åå†è¯•';
            } else {
                reason = 'API è°ƒç”¨å¤±è´¥';
                suggestion = errorMessage.substring(0, 100);
            }
            
            const message = `ğŸš¨ è¯­éŸ³å¼•æ“é™çº§é€šçŸ¥\n\n` +
                          `ä» ${fromEngine.toUpperCase()} é™çº§åˆ° ${toEngine.toUpperCase()}\n` +
                          `åŸå› : ${reason}\n` +
                          `å»ºè®®: ${suggestion}\n\n` +
                          `æ—¶é—´: ${new Date().toLocaleString('zh-CN', { timeZone: 'Asia/Shanghai' })}`;
            
            console.log('[Voice] ğŸ“¤ å‘é€é™çº§é€šçŸ¥åˆ° OpenClaw');
            
            // å‘é€åˆ° OpenClaw Gateway (desktop-bridge.js ä¼šè½¬å‘åˆ°é£ä¹¦)
            const payload = JSON.stringify({
                action: 'agent-response',
                text: message
            });
            
            const options = {
                hostname: 'localhost',
                port: 18788,
                path: '/notify',
                method: 'POST',
                headers: {
                    'Content-Type': 'application/json',
                    'Content-Length': Buffer.byteLength(payload)
                }
            };
            
            const req = http.request(options, (res) => {
                console.log(`[Voice] âœ… é™çº§é€šçŸ¥å·²å‘é€ (çŠ¶æ€: ${res.statusCode})`);
            });
            
            req.on('error', (err) => {
                console.error('[Voice] âŒ é™çº§é€šçŸ¥å‘é€å¤±è´¥:', err.message);
            });
            
            req.write(payload);
            req.end();
            
        } catch (err) {
            console.error('[Voice] âŒ notifyDegradation å¤±è´¥:', err.message);
        }
    }

    /**
     * ğŸ§¹ æ¸…ç†ä¸´æ—¶æ–‡ä»¶
     */
    async cleanupTempFiles(keepCount = 50) {
        try {
            const files = await fs.readdir(this.tempDir);
            const mp3Files = files.filter(f => f.endsWith('.mp3'));
            
            if (mp3Files.length <= keepCount) {
                return { deleted: 0, freed: 0 };
            }
            
            const fileStats = await Promise.all(
                mp3Files.map(async (file) => {
                    const filePath = path.join(this.tempDir, file);
                    const stat = await fs.stat(filePath);
                    return { file, path: filePath, mtime: stat.mtime, size: stat.size };
                })
            );
            
            fileStats.sort((a, b) => b.mtime - a.mtime);
            const toDelete = fileStats.slice(keepCount);
            
            let deleted = 0;
            let freed = 0;
            
            for (const item of toDelete) {
                try {
                    await fs.unlink(item.path);
                    deleted++;
                    freed += item.size;
                } catch (err) {}
            }
            
            if (deleted > 0) {
                console.log(`ğŸ§¹ æ¸…ç†è¯­éŸ³æ–‡ä»¶: ${deleted}ä¸ª, ${(freed / 1024).toFixed(1)}KB`);
            }
            
            return { deleted, freed };
        } catch (err) {
            return { deleted: 0, freed: 0 };
        }
    }
}

module.exports = SmartVoiceSystem;
